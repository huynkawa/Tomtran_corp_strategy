# ğŸ“ src/build_index_clean_ready.py
# Build vector store tá»« dá»¯ liá»‡u sáº¡ch trong inputs/clean_ready

import os, json, shutil, argparse, hashlib
from pathlib import Path
from tqdm import tqdm
from dotenv import load_dotenv
from langchain.schema import Document
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from src.config import make_embeddings
from src.build_index_clean_ocr_data import (
    chunk_documents, load_clean_docs, dedupe_docs_by_content
)

load_dotenv()

INPUT_DIR = Path(r"D:/1.TLAT/3. ChatBot_project/1_Insurance_Strategy - Copy/inputs/clean_ready")
VECTOR_BASE = Path(r"D:/1.TLAT/3. ChatBot_project/1_Insurance_Strategy - Copy/vector_store/clean_ready")

def get_relative_path(base: Path, target: Path) -> Path:
    """Tráº£ vá» Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i cá»§a target so vá»›i base."""
    try:
        return target.relative_to(base)
    except ValueError:
        return target

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--table-mode", choices=["rows", "sheet"], default="rows")
    ap.add_argument("--chunk-size", type=int, default=900)
    ap.add_argument("--chunk-overlap", type=int, default=120)
    ap.add_argument("--dedupe", choices=["on", "off"], default="on")
    ap.add_argument("--index-overview", choices=["on", "off"], default="off")
    args = ap.parse_args()

    built, skipped = 0, 0

    all_files = list(INPUT_DIR.rglob("*"))
    valid_ext = (".xlsx", ".csv", ".txt")

    for f in all_files:
        if not f.is_file() or f.suffix.lower() not in valid_ext:
            continue

        rel_path = get_relative_path(INPUT_DIR, f)
        vec_dir = VECTOR_BASE / rel_path.parent / f.stem

        company_tag = f.stem.strip().lower()
        os.makedirs(vec_dir.parent, exist_ok=True)

        choice = "y"
        if os.path.exists(vec_dir):
            choice = input(f"âš ï¸ Vector store '{vec_dir}' Ä‘Ã£ tá»“n táº¡i.\n"
                           "  y = xoÃ¡ build láº¡i | a = append thÃªm | n = bá» qua  â†’ ").strip().lower()

        if choice == "y":
            shutil.rmtree(vec_dir, ignore_errors=True)
            print(f"ğŸ—‘ï¸ ÄÃ£ xoÃ¡ {vec_dir}")
        elif choice == "n":
            print(f"â­ï¸ Bá» qua {f.name}")
            skipped += 1
            continue
        elif choice == "a":
            print(f"â• Append dá»¯ liá»‡u vÃ o {vec_dir}")
        else:
            print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡, bá» qua.")
            skipped += 1
            continue

        print(f"\nğŸ“¥ Náº¡p dá»¯ liá»‡u tá»« file: {f}")
        docs = load_clean_docs(str(f), table_mode=args.table_mode,
                               index_overview=(args.index_overview == "on"),
                               company_tag=company_tag)
        if args.dedupe == "on":
            docs = dedupe_docs_by_content(docs)

        chunks = chunk_documents(docs, chunk_size=args.chunk_size, chunk_overlap=args.chunk_overlap)
        os.makedirs(vec_dir, exist_ok=True)
        embeddings = make_embeddings()

        if choice == "a" and os.path.exists(vec_dir):
            db = Chroma(persist_directory=str(vec_dir), embedding=embeddings)
            db.add_documents(tqdm(chunks, desc=f"[append] {company_tag}", unit="chunk"))
            db.persist()
        else:
            Chroma.from_documents(
                documents=tqdm(chunks, desc=f"[embedding] {company_tag}", unit="chunk"),
                embedding=embeddings,
                persist_directory=str(vec_dir)
            )

        print(f"âœ… ÄÃ£ lÆ°u vector: {vec_dir} | docs={len(docs)} | chunks={len(chunks)}")
        built += 1

    print("\n=== TÃ“M Táº®T BUILD VECTOR ===")
    print(f"ğŸ“‚ Tá»•ng sá»‘ vector Ä‘Ã£ build: {built}")
    print(f"â­ï¸ Tá»•ng sá»‘ bá» qua: {skipped}")

if __name__ == "__main__":
    main()
