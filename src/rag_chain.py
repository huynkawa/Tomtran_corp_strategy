from src.reranker import rerank
import os
from openai import OpenAI
import time  # c·∫ßn ƒë·ªÉ d√πng sleep

def retrieve_context_any(db_or_retriever, query, k=12, min_relev=0.2):
    """
    L·∫•y context t·ª´ vectordb ho·∫∑c retriever.
    Tr·∫£ v·ªÅ (ctx_text, docs, ok).
    """
    docs = []
    try:
        # ∆Øu ti√™n vectordb (Chroma)
        if hasattr(db_or_retriever, "similarity_search_with_relevance_scores"):
            pairs = db_or_retriever.similarity_search_with_relevance_scores(query, k=k)
            docs = [d for (d, s) in pairs if (s is not None and s >= min_relev)]
            if not docs:  # n·∫øu kh√¥ng ƒë·ªß ƒëi·ªÉm th√¨ l·∫•y t·∫•t c·∫£
                docs = [d for (d, _) in pairs]

        # N·∫øu kh√¥ng ph·∫£i vectordb, fallback sang retriever
        elif hasattr(db_or_retriever, "get_relevant_documents"):
            docs = db_or_retriever.get_relevant_documents(query)

    except Exception as e:
        print("[rag_chain] ‚ùå retrieve_context_any error:", e)
        docs = []

    ok = bool(docs)
    ctx_text = "\n\n".join(d.page_content for d in docs) if docs else ""
    return ctx_text, docs, ok


def wait_for_completion(client, thread_id, run_id, timeout=60):
    """Poll Assistant API cho ƒë·∫øn khi c√≥ k·∫øt qu·∫£ ho·∫∑c h·∫øt timeout"""
    start = time.time()
    while time.time() - start < timeout:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)
        if run_status.status == "completed":
            messages = client.beta.threads.messages.list(thread_id=thread_id)
            # L·∫•y message cu·ªëi c√πng c·ªßa assistant
            for m in messages.data:
                if m.role == "assistant":
                    return m.content[0].text.value
            return "(Kh√¥ng nh·∫≠n ƒë∆∞·ª£c message t·ª´ Assistant)"
        elif run_status.status in ["failed", "cancelled", "expired"]:
            return f"(Assistant run error: {run_status.status})"
        time.sleep(1)
    return "(Timeout khi ch·ªù Assistant tr·∫£ l·ªùi)"


def rag_answer(query, retriever_or_db, client=None, use_fallback=True, threshold=0.2, k=12, debug=False):
    """
    Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n t√†i li·ªáu (RAG) b·∫±ng Assistant API.
    Tr·∫£ v·ªÅ dict:
      {
        "answer": str,
        "source": "internal" | "general" | "none",
        "ctx_text": str,
        "docs": list
      }
    """
    ctx_text, docs, ok = retrieve_context_any(retriever_or_db, query, k=k, min_relev=threshold)

    api_key = os.getenv("OPENAI_API_KEY")
    assistant_id = os.getenv("ASSISTANT_ID")
    if not assistant_id:
        return {
            "answer": "‚ùå Thi·∫øu ASSISTANT_ID trong .env.active",
            "source": "none",
            "ctx_text": ctx_text if ok else "",
            "docs": docs if ok else [],
        }

    client = client or OpenAI(api_key=api_key)

    if not hasattr(rag_answer, "_thread"):
        rag_answer._thread = client.beta.threads.create()

    # --- N·∫øu c√≥ context n·ªôi b·ªô ---
    if ok:
        reranked = rerank(query, docs, top_n=3, return_scores=True)
        docs = [d for d, _ in reranked]
        ctx_text = "\n\n".join(d.page_content for d in docs)

        if debug:
            print(f"[rerank] Query: {query}")
            for d, score in reranked:
                print(f"   - Score={score:.4f} | Source={d.metadata.get('source', 'unknown')}")

        # So·∫°n prompt cho Assistant
        prompt = f"""
D·ªØ li·ªáu n·ªôi b·ªô (context):
{ctx_text}

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng:
{query}

H√£y tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu n·ªôi b·ªô n·∫øu c√≥.
N·∫øu kh√¥ng c√≥, h√£y d√πng ki·∫øn th·ª©c chung (v√† n√™u r√µ ngu·ªìn).
""".strip()

        # T·∫°o message trong thread
        client.beta.threads.messages.create(
            thread_id=rag_answer._thread.id,
            role="user",
            content=prompt
        )

        # T·∫°o run
        run = client.beta.threads.runs.create(
            thread_id=rag_answer._thread.id,
            assistant_id=assistant_id
        )
        print(f"[AssistantAPI] üöÄ Run created: {run.id} | Assistant: {assistant_id}")

        # ƒê·ª£i Assistant tr·∫£ l·ªùi
        answer_text = wait_for_completion(client, rag_answer._thread.id, run.id)

        print(f"[AssistantAPI] ‚úÖ Assistant tr·∫£ l·ªùi xong | Run={run.id}")
        print(f"[AssistantAPI] ‚úçÔ∏è Answer (preview): {answer_text[:200]}...")

        return {
            "answer": answer_text,
            "source": "internal",
            "ctx_text": ctx_text,
            "docs": docs,
        }

    # --- N·∫øu kh√¥ng c√≥ context v√† cho ph√©p fallback ---
    if use_fallback:
        client.beta.threads.messages.create(
            thread_id=rag_answer._thread.id,
            role="user",
            content=query
        )

        run = client.beta.threads.runs.create(
            thread_id=rag_answer._thread.id,
            assistant_id=assistant_id
        )
        print(f"[AssistantAPI] üöÄ Run created (fallback): {run.id} | Assistant: {assistant_id}")

        answer_text = wait_for_completion(client, rag_answer._thread.id, run.id)
