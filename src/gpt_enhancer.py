# -*- coding: utf-8 -*-
"""
src/gpt_enhancer.py ‚Äî GPT enhancer cho TABLE & TEXT
- TABLE:
    + mode="financial": BCTC (√©p format CODE | NAME | NOTE | END | BEGIN)
    + mode="generic"  : b·∫£ng th∆∞·ªùng (c·ªôt linh ho·∫°t, ngƒÉn b·∫±ng '|')
    + ∆Øu ti√™n ·∫¢NH n·∫øu c√≥; fallback v·ªÅ b·∫£n YAML-clean n·∫øu GPT l·ªói/format sai
    + Guardrail: ki·ªÉm ƒë·ªãnh d·∫°ng '|', s·ªë c·ªôt t·ªëi thi·ªÉu, sanity check nh·∫π cho BCTC
- TEXT:
    + Clean nh·∫π vƒÉn b·∫£n th∆∞·ªùng (kh√¥ng ƒë·ªïi sang b·∫£ng/markdown)
- Backward-compat:
    + Cung c·∫•p h√†m enhance_with_gpt(...) ƒë·ªÉ gi·ªØ t∆∞∆°ng th√≠ch ng∆∞·ª£c v·ªõi code c≈©
"""

from __future__ import annotations
import os, io, time, base64, json, re
from typing import Optional, List, Tuple, Dict, Any
from PIL import Image

# (t√πy) n·∫°p env key s·ªõm (n·∫øu b·∫°n c√≥ src.env ƒë·ªÉ load .env.active)
try:
    import src.env  # noqa
except Exception:
    pass

# OpenAI client (phi√™n b·∫£n v1+)
try:
    from openai import OpenAI
    _OPENAI_OK = True
except Exception:
    _OPENAI_OK = False


# ---------- Heuristic nh·∫≠n d·∫°ng b·∫£ng BCTC ----------
_FIN_HINTS = [
    r"\bm√£\s*s·ªë\b", r"\bch·ªâ\s*t[i√≠]√™u\b",
    r"\bs·ªë\s*cu·ªëi\s*nƒÉm\b", r"\bs·ªë\s*ƒë·∫ßu\s*nƒÉm\b",
    r"\bcode\b", r"\bend\b", r"\bbegin\b",
    r"\bassets\b", r"\bequity\b", r"\bliabilities\b"
]
_FIN_CODE_PAT = r"\b\d{2,3}(?:\.\d+)?\b"  # 100, 131, 131.1, 329.2,...

def detect_table_domain(clean_text: str) -> str:
    t = (clean_text or "").lower()
    if any(re.search(p, t, re.I) for p in _FIN_HINTS) and re.search(_FIN_CODE_PAT, t):
        return "financial"
    return "generic"


# ---------- Schema & Prompt builder ----------
def _schema_for_mode(mode: str, as_json: bool = False) -> Dict[str, Any]:
    mode = (mode or "financial").lower()
    if mode == "financial":
        if as_json:
            sys = (
                "B·∫°n l√† chuy√™n gia ki·ªÉm ƒë·ªãnh b·∫£ng b√°o c√°o t√†i ch√≠nh (phi nh√¢n th·ªç, VN). "
                "ƒê·ªçc K·ª∏ b·∫£ng trong ·∫¢NH v√† ƒë·ªëi chi·∫øu v·ªõi vƒÉn b·∫£n OCR ƒë√£ l√†m s·∫°ch. "
                "N·∫øu m√¢u thu·∫´n, TIN ·∫¢NH H∆†N. KH√îNG B·ªäA. "
                "TR·∫¢ V·ªÄ JSON (list c√°c h√†ng), m·ªói h√†ng l√† object c√≥ kh√≥a: "
                "CODE, NAME, NOTE, END, BEGIN. NOTE c√≥ th·ªÉ r·ªóng. "
                "END/BEGIN d√πng ƒë·ªãnh d·∫°ng s·ªë ki·ªÉu VN d∆∞·ªõi d·∫°ng chu·ªói (v√≠ d·ª• '1.234.567'). "
                "KH√îNG in th√™m gi·∫£i th√≠ch/markdown."
            )
        else:
            sys = (
                "B·∫°n l√† chuy√™n gia ki·ªÉm ƒë·ªãnh b·∫£ng b√°o c√°o t√†i ch√≠nh (phi nh√¢n th·ªç, VN). "
                "ƒê·ªçc K·ª∏ b·∫£ng trong ·∫¢NH v√† ƒë·ªëi chi·∫øu v·ªõi vƒÉn b·∫£n OCR ƒë√£ l√†m s·∫°ch. "
                "N·∫øu m√¢u thu·∫´n, TIN ·∫¢NH H∆†N. KH√îNG B·ªäA. "
                "ƒê·∫¶U RA: TEXT THU·∫¶N; m·ªói d√≤ng 1 h√†ng; c·ªôt theo th·ª© t·ª±: "
                "CODE | NAME | NOTE | END | BEGIN. "
                "N·∫øu kh√¥ng c√≥ NOTE, ƒë·ªÉ tr·ªëng gi·ªØa hai d·∫•u '|'. "
                "END/BEGIN ƒë·ªãnh d·∫°ng s·ªë ki·ªÉu VN (1.234.567). "
                "Kh√¥ng in ti√™u ƒë·ªÅ/markdown/gi·∫£i th√≠ch."
            )
        return {"name": "financial", "min_cols": 4, "max_cols": 5, "sys": sys}
    else:
        if as_json:
            sys = (
                "B·∫°n l√† chuy√™n gia tr√≠ch b·∫£ng trong ·∫¢NH th√†nh JSON. "
                "ƒê·ªçc K·ª∏ ·∫¢NH v√† ƒë·ªëi chi·∫øu v·ªõi vƒÉn b·∫£n OCR ƒë√£ l√†m s·∫°ch. "
                "N·∫øu m√¢u thu·∫´n, TIN ·∫¢NH H∆†N. KH√îNG B·ªäA. "
                "TR·∫¢ V·ªÄ JSON: danh s√°ch c√°c h√†ng; m·ªói h√†ng l√† list c√°c c·ªôt theo th·ª© t·ª± tr√°i‚Üíph·∫£i. "
                "Kh√¥ng in th√™m gi·∫£i th√≠ch/markdown."
            )
        else:
            sys = (
                "B·∫°n l√† chuy√™n gia chuy·ªÉn b·∫£ng trong ·∫¢NH th√†nh TEXT c√≥ c·ªôt. "
                "ƒê·ªçc K·ª∏ ·∫¢NH v√† ƒë·ªëi chi·∫øu v·ªõi vƒÉn b·∫£n OCR ƒë√£ l√†m s·∫°ch. "
                "N·∫øu m√¢u thu·∫´n, TIN ·∫¢NH H∆†N. KH√îNG B·ªäA. "
                "ƒê·∫¶U RA: TEXT THU·∫¶N; m·ªói d√≤ng 1 h√†ng; c·ªôt ngƒÉn b·∫±ng '|', gi·ªØ th·ª© t·ª± tr√°i‚Üíph·∫£i. "
                "Kh√¥ng in ti√™u ƒë·ªÅ/markdown/gi·∫£i th√≠ch. "
                "N·∫øu s·ªë c·ªôt thay ƒë·ªïi gi·ªØa c√°c h√†ng, v·∫´n in ƒë√∫ng theo quan s√°t."
            )
        return {"name": "generic", "min_cols": 3, "max_cols": None, "sys": sys}


# ---------- Utilities ----------
def _pil_to_b64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode("utf-8")

def _retry(fn, n=2, delay=1.0):
    err = None
    for i in range(n + 1):
        try:
            return fn()
        except Exception as e:
            err = e
            if i < n:
                time.sleep(delay * (2 ** i))
    raise err

def _postprocess_table_text(out: str, max_cols: Optional[int]) -> str:
    """Chu·∫©n ho√° kho·∫£ng tr·∫Øng quanh '|', c·∫Øt c·ªôt d∆∞ n·∫øu max_cols ƒë∆∞·ª£c ƒë·∫∑t."""
    lines = []
    for ln in (out or "").splitlines():
        ln = ln.strip()
        if not ln:
            continue
        ln = re.sub(r"\s*\|\s*", " | ", ln)
        ln = re.sub(r"^\|\s*", "", ln)
        ln = re.sub(r"\s*\|$", "", ln)
        parts = [p.strip() for p in ln.split("|")]
        if max_cols and len(parts) > max_cols:
            parts = parts[:max_cols]
        ln = " | ".join(parts)
        lines.append(ln)
    return "\n".join(lines)

def _basic_guardrail_text(text: str, min_cols: int) -> bool:
    if not text:
        return False
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    if not lines:
        return False
    if all("|" not in ln for ln in lines):
        return False
    for ln in lines:
        if ln.count("|") + 1 < min_cols:
            return False
    return True

# parse TEXT d·∫°ng 'code | name | note | end | begin'
def _parse_financial_rows_text(text: str) -> List[Tuple[str, str, str, str, str]]:
    rows = []
    for ln in (text or "").splitlines():
        parts = [p.strip() for p in ln.split("|")]
        if len(parts) < 4:
            continue
        if len(parts) == 4:
            code, name, end, begin = parts
            note = ""
        else:
            code, name, note, end, begin = (parts + [""] * 5)[:5]
        rows.append((code, name, note, end, begin))
    return rows

_num_clean_re = re.compile(r"[^\d\.]")

def _to_number_like(s: str) -> Optional[int]:
    """Chuy·ªÉn '1.234.567' ‚Üí 1234567; n·∫øu fail tr·∫£ None."""
    if s is None:
        return None
    raw = _num_clean_re.sub("", s or "")
    if not raw:
        return None
    try:
        return int(raw.replace(".", ""))
    except Exception:
        return None

def _sanity_check_financial_text(out: str) -> bool:
    """Ki·ªÉm tra nhanh: c√≥ m√£ t·ªïng quan tr·ªçng, v√† s·ªë END/BEGIN parse ƒë∆∞·ª£c."""
    rows = _parse_financial_rows_text(out)
    if not rows:
        return False
    codes = {r[0] for r in rows}
    if not codes.intersection({"100", "200", "270", "300", "400", "440"}):
        return False
    parsed_any = any((_to_number_like(end) is not None or _to_number_like(begin) is not None)
                     for _, _, _, end, begin in rows)
    return parsed_any

def _build_user_payload(table_text_cleaned: str, meta: Optional[dict]) -> List[dict]:
    user_text = (
        "VƒÇN B·∫¢N ƒê√É L√ÄM S·∫†CH (B·∫¢NG):\n"
        "-----BEGIN CLEANED TEXT-----\n"
        f"{table_text_cleaned}\n"
        "-----END CLEANED TEXT-----\n\n"
        "Y√äU C·∫¶U:\n"
        "- So v√† s·ª≠a theo ·∫¢NH (n·∫øu c√≥) ‚Äî ∆∞u ti√™n ·∫¢NH khi m√¢u thu·∫´n.\n"
        "- Tr·∫£ K·∫æT QU·∫¢ cu·ªëi c√πng v·ªõi m·ªói d√≤ng 1 h√†ng; c·ªôt ngƒÉn b·∫±ng '|'.\n"
        "- Kh√¥ng th√™m gi·∫£i th√≠ch/markdown."
    )
    content = [{"type": "text", "text": user_text}]
    if meta:
        content.insert(0, {"type": "text", "text": "Meta (tham kh·∫£o, KH√îNG in ra):\n" + json.dumps(meta, ensure_ascii=False, indent=2)})
    return content


# ---------- API ch√≠nh: TABLE ----------
def enhance_table_with_gpt(
    table_text_cleaned: str,
    image_pil: Optional[Image.Image] = None,
    meta: Optional[dict] = None,
    mode: Optional[str] = None,
    model: str = "gpt-4o-mini",
    temperature: float = 0.0,
    max_tokens: int = 3000,
    as_json: bool = False,
    log_diag: bool = True,
) -> str | List[Dict[str, Any]]:
    """
    Cross-check ·∫£nh (n·∫øu c√≥) + text ƒë√£ clean (YAML) ‚Üí tr·∫£ b·∫£ng theo schema mode.
    - mode=None ‚Üí auto-detect (financial/generic)
    - as_json=True ‚Üí tr·∫£ JSON; False ‚Üí TEXT.
    - Fallback: tr·∫£ l·∫°i table_text_cleaned n·∫øu GPT l·ªói/format sai
    """
    if not _OPENAI_OK or not os.getenv("OPENAI_API_KEY"):
        if log_diag:
            print("‚ö†Ô∏è GPT skipped: OPENAI_API_KEY missing ho·∫∑c OpenAI lib kh√¥ng kh·∫£ d·ª•ng.")
        return table_text_cleaned

    # auto detect n·∫øu kh√¥ng truy·ªÅn mode
    mode = mode or detect_table_domain(table_text_cleaned)
    schema = _schema_for_mode(mode, as_json=as_json)

    # build messages
    content = _build_user_payload(table_text_cleaned, meta)
    if image_pil is not None:
        content.append({"type": "image_url", "image_url": {"url": f"data:image/png;base64,{_pil_to_b64(image_pil)}"}})

    def _call():
        client = OpenAI()
        return client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": schema["sys"]},
                      {"role": "user", "content": content}],
            temperature=temperature,
            max_tokens=max_tokens,
        )

    try:
        resp = _retry(_call, n=2, delay=1.0)
        out = (resp.choices[0].message.content or "").strip()

        # log token n·∫øu c√≥
        if log_diag:
            used = getattr(getattr(resp, "usage", None), "total_tokens", None)
            print(f"üß† GPT ok. mode={schema['name']} as_json={as_json} tokens‚âà{used if used is not None else '?'}")

        if as_json:
            # m·ªôt s·ªë model c√≥ th·ªÉ b·ªçc ```json ...```
            raw = out.strip()
            if raw.startswith("```"):
                raw = re.sub(r"^```json\s*|\s*```$", "", raw, flags=re.I | re.M)
            try:
                data = json.loads(raw)
            except Exception:
                if log_diag:
                    print("‚ö†Ô∏è JSON parse fail ‚Üí fallback cleaned text.")
                return table_text_cleaned

            if schema["name"] == "financial":
                ok = isinstance(data, list) and all(isinstance(r, dict) for r in data)
                ok = ok and all(set(r.keys()) >= {"CODE", "NAME", "END", "BEGIN"} for r in data)
                if not ok:
                    if log_diag:
                        print("‚ö†Ô∏è JSON financial format invalid ‚Üí fallback.")
                    return table_text_cleaned
            else:
                ok = isinstance(data, list) and all(isinstance(r, (list, tuple)) for r in data)
                if not ok:
                    if log_diag:
                        print("‚ö†Ô∏è JSON generic format invalid ‚Üí fallback.")
                    return table_text_cleaned
            return data

        # TEXT mode: post-process + guardrail
        out = _postprocess_table_text(out, max_cols=schema.get("max_cols"))
        if not _basic_guardrail_text(out, schema["min_cols"]):
            if log_diag:
                print("‚ö†Ô∏è GPT output format invalid ‚Üí fallback cleaned text.")
            return table_text_cleaned

        if schema["name"] == "financial" and not _sanity_check_financial_text(out):
            if log_diag:
                print("‚ö†Ô∏è Financial sanity check failed ‚Üí fallback.")
            return table_text_cleaned

        return out

    except Exception as e:
        if log_diag:
            print(f"‚ö†Ô∏è OpenAI error ‚Üí fallback cleaned text: {e}")
        return table_text_cleaned


# ---------- API ph·ª•: TEXT (vƒÉn b·∫£n th∆∞·ªùng) ----------
def _enhance_plain_text_with_gpt(text_raw: str,
                                 meta: dict | None = None,
                                 model: str = "gpt-4o-mini",
                                 temperature: float = 0.2,
                                 max_tokens: int = 2000,
                                 log_diag: bool = True) -> str:
    """
    D√πng khi mu·ªën clean VƒÇN B·∫¢N TH∆Ø·ªúNG (kh√¥ng ph·∫£i b·∫£ng).
    L√†m s·∫°ch nh·∫π: s·ª≠a l·ªói OCR nh·ªè, n·ªëi d√≤ng g√£y, gi·ªØ nguy√™n n·ªôi dung; kh√¥ng ƒë·ªïi sang b·∫£ng/markdown.
    """
    if not _OPENAI_OK or not os.getenv("OPENAI_API_KEY"):
        if log_diag:
            print("‚ö†Ô∏è GPT skipped (plain-text): OPENAI_API_KEY missing ho·∫∑c OpenAI lib kh√¥ng kh·∫£ d·ª•ng.")
        return text_raw

    sys_prompt = (
        "B·∫°n l√† bi√™n t·∫≠p vi√™n OCR. H√£y l√†m s·∫°ch ƒëo·∫°n vƒÉn sau: s·ª≠a l·ªói ch√≠nh t·∫£ OCR nh·ªè, "
        "n·ªëi d√≤ng g√£y, gi·ªØ nguy√™n n·ªôi dung/√Ω, KH√îNG th√™m/b·ªõt, KH√îNG ƒë·ªïi th√†nh b·∫£ng hay th√™m markdown. "
        "Tr·∫£ ra ƒë√∫ng vƒÉn b·∫£n s·∫°ch, thu·∫ßn text."
    )
    content = []
    if meta:
        content.append({"type": "text", "text": "Meta (tham kh·∫£o, KH√îNG in ra):\n" + json.dumps(meta, ensure_ascii=False, indent=2)})
    content.append({"type": "text", "text": text_raw})

    def _call():
        client = OpenAI()
        return client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": sys_prompt},
                      {"role": "user", "content": content}],
            temperature=temperature,
            max_tokens=max_tokens,
        )

    try:
        resp = _retry(_call, n=2, delay=1.0)
        out = (resp.choices[0].message.content or "").strip()
        if log_diag:
            used = getattr(getattr(resp, "usage", None), "total_tokens", None)
            print(f"üß† GPT ok (plain-text). tokens‚âà{used if used is not None else '?'}")
        return out or text_raw
    except Exception as e:
        if log_diag:
            print(f"‚ö†Ô∏è OpenAI error (plain-text) ‚Üí fallback: {e}")
        return text_raw


# =======================
# Backward-compat shim(s)
# =======================
def enhance_with_gpt(
    text_raw: str,
    meta: dict | None = None,
    image_path: str | None = None,
    mode: str | None = None,
    **kwargs
) -> str:
    """
    T∆∞∆°ng th√≠ch ng∆∞·ª£c v·ªõi code c≈©:
    - N·∫øu c√≥ ·∫£nh ho·∫∑c n·ªôi dung tr√¥ng nh∆∞ B·∫¢NG ‚Üí g·ªçi enhance_table_with_gpt
    - Ng∆∞·ª£c l·∫°i ‚Üí clean vƒÉn b·∫£n th∆∞·ªùng b·∫±ng _enhance_plain_text_with_gpt
    """
    # Heuristic: n·∫øu c√≥ d·∫•u '|' nhi·ªÅu ho·∫∑c cues BCTC ‚Üí coi nh∆∞ b·∫£ng
    looks_like_table = False
    t = (text_raw or "").lower()
    if ("|" in t and t.count("|") >= 2) or re.search(
        r"\bm√£\s*s·ªë\b|\bs·ªë\s*cu·ªëi\s*nƒÉm\b|\bs·ªë\s*ƒë·∫ßu\s*nƒÉm\b|\bcode\b", t, re.I
    ):
        looks_like_table = True

    pil = None
    if image_path and os.path.exists(image_path):
        try:
            pil = Image.open(image_path)
        except Exception:
            pil = None

    if looks_like_table or pil is not None:
        mode_eff = mode or ("financial" if looks_like_table else "generic")
        return enhance_table_with_gpt(
            table_text_cleaned=text_raw,
            image_pil=pil,
            meta=meta,
            mode=mode_eff,
            **kwargs
        )

    # VƒÉn b·∫£n th∆∞·ªùng
    return _enhance_plain_text_with_gpt(
        text_raw=text_raw,
        meta=meta,
        **{k: v for k, v in kwargs.items() if k in {"model", "temperature", "max_tokens", "log_diag"}}
    )
