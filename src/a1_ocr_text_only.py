# -*- coding: utf-8 -*-
"""
a1_ocr_text_only.py ‚Äî OCR v√† ƒë·ªçc vƒÉn b·∫£n ƒëa ƒë·ªãnh d·∫°ng (PDF, DOCX, EXCEL, CSV, IMAGE)

M·ª•c ti√™u:
---------
- ƒê·ªçc t·∫•t c·∫£ c√°c lo·∫°i t√†i li·ªáu (PDF, DOCX, XLSX, CSV, IMAGE, TXT)
- Kh√¥ng sinh ra b·∫•t k·ª≥ file CSV/Excel n√†o.
- Chuy·ªÉn to√†n b·ªô n·ªôi dung (k·ªÉ c·∫£ b·∫£ng scan, s∆° ƒë·ªì) sang text duy nh·∫•t.
- Xu·∫•t ƒë√∫ng 2 file/trang:
    <base>_page{n}_text.txt
    <base>_page{n}_meta.json
- Gi·ªØ c·∫•u tr√∫c th∆∞ m·ª•c mirror t·ª´ inputs sang outputs.
- Khi OCR ·∫£nh ho·∫∑c PDF scan ‚Üí t·ª± ƒë·ªông d√πng thu·∫≠t to√°n TSV reflow ƒë·ªÉ t√°i c·∫•u tr√∫c b·∫£ng.

ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh:
-------------------
Input : D:\\1.TLAT\\3. ChatBot_project\\1_Insurance_Strategy\\inputs\\a_text_only_inputs
Output: D:\\1.TLAT\\3. ChatBot_project\\1_Insurance_Strategy\\outputs\\a_text_only_outputs

Y√™u c·∫ßu th∆∞ vi·ªán:
-----------------
pip install pdf2image pillow opencv-python-headless numpy pytesseract python-docx pandas openpyxl tqdm
v√† c√†i ƒë·∫∑t Tesseract (tesseract.exe c√≥ trong PATH ho·∫∑c ƒë·∫∑t env TESSERACT_CMD)
"""

from __future__ import annotations
import os, re, glob, json, argparse, hashlib, shutil, time
from typing import Optional, Tuple, Dict, List
from pathlib import Path

import numpy as np
import cv2
from PIL import Image
import pytesseract
from pdf2image import convert_from_path
from pytesseract import Output as TessOutput
import pandas as pd
from tqdm import tqdm

try:
    import docx
except ImportError:
    docx = None


# =========================
# ‚öôÔ∏è C·∫§U H√åNH C∆† B·∫¢N
# =========================
INPUT_DIR_DEFAULT = r"D:\1.TLAT\3. ChatBot_project\1_Insurance_Strategy\inputs\a_text_only_inputs_test"
OUTPUT_DIR_DEFAULT = r"D:\1.TLAT\3. ChatBot_project\1_Insurance_Strategy\outputs\a_text_only_outputs"
OCR_LANG_DEFAULT = "vie+eng"
OCR_CFG_DEFAULT = "--psm 6 preserve_interword_spaces=1"
APPEND_MODE = False

TESSERACT_CMD = os.environ.get("TESSERACT_CMD", None)
if TESSERACT_CMD and os.path.isfile(TESSERACT_CMD):
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD


# =========================
# ‚öôÔ∏è H√ÄM H·ªñ TR·ª¢ CHUNG
# =========================
def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)

def clean_txt_chars(s: str) -> str:
    """Chu·∫©n ho√° vƒÉn b·∫£n OCR: lo·∫°i k√Ω t·ª± r√°c v√† kho·∫£ng tr·∫Øng th·ª´a"""
    if not s: return ""
    s = re.sub(r"[|¬¶‚Ä¢ÔÇ∑ÔÇü‚àô¬∑]+", " ", s)
    s = re.sub(r"[^\S\r\n]{2,}", " ", s)
    s = re.sub(r"[^\x20-\x7E\u00A0-\uFFFF]", " ", s)
    return s.strip()

def _sha1_text(s: str) -> str:
    return hashlib.sha1((s or "").encode("utf-8")).hexdigest()

def _strip_vn_accents(s: str) -> str:
    rep = {
        "ƒë":"d","∆°":"o","√¥":"o","∆∞":"u","ƒÉ":"a","√¢":"a","√°":"a","√†":"a","·∫£":"a","√£":"a","·∫°":"a",
        "√©":"e","√®":"e","·∫ª":"e","·∫Ω":"e","·∫π":"e","√≠":"i","√¨":"i","·ªâ":"i","ƒ©":"i","·ªã":"i",
        "√≥":"o","√≤":"o","·ªè":"o","√µ":"o","·ªç":"o","√∫":"u","√π":"u","·ªß":"u","≈©":"u","·ª•":"u",
        "√Ω":"y","·ª≥":"y","·ª∑":"y","·ªπ":"y","·ªµ":"y"
    }
    s = (s or "").lower()
    for k,v in rep.items():
        s = s.replace(k, v)
    return re.sub(r"\s+", " ", s).strip()

def detect_language(text: str) -> str:
    if not text: return "vi"
    vi_marks = re.findall(r"[ƒÉ√¢√™√¥∆°∆∞ƒë√°√†·∫£√£·∫°√©√®·∫ª·∫Ω·∫π√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√∫√π·ªß≈©·ª•√Ω·ª≥·ª∑·ªπ·ªµ]", text.lower())
    if len(vi_marks) >= 3: return "vi"
    if re.search(r"\b(January|February|March|April|May|June|July|August|September|October|November|December)\b", text, re.IGNORECASE):
        return "en"
    return "vi"


# =========================
# ‚öôÔ∏è TSV REFLOW t·ª´ p1a_clean10_ocr_bctc.py
# =========================
def reflow_lines_from_tsv_dict(data: Dict[str, List], y_tol: int = 4) -> str:
    """Gh√©p d√≤ng TSV Tesseract th√†nh vƒÉn b·∫£n m·∫°ch l·∫°c h∆°n (ph·ª•c v·ª• ·∫£nh scan c√≥ b·∫£ng)."""
    n = len(data.get("text", []))
    groups: Dict[Tuple[int,int,int], List[int]] = {}
    for i in range(n):
        t = (data["text"][i] or "").strip()
        if not t: continue
        key = (int(data["block_num"][i]), int(data["par_num"][i]), int(data["line_num"][i]))
        groups.setdefault(key, []).append(i)

    lines = []
    for key, idxs in sorted(groups.items()):
        idxs = sorted(idxs, key=lambda k: int(data["left"][k]))
        txt = " ".join((data["text"][k] or "").strip() for k in idxs).strip()
        if not txt: continue
        y = int(min(int(data["top"][k]) for k in idxs))
        lines.append({"y": y, "text": txt})

    lines.sort(key=lambda r: r["y"])

    out_lines = []
    for ln in lines:
        s = ln["text"]
        # √©p xu·ªëng d√≤ng tr∆∞·ªõc c√°c m√£ s·ªë, m·ª•c l·ªõn, s·ªë ti·ªÅn
        s = re.sub(r"(?<!^)\s(?=\d{3}(?:\.\d+)?\b)", "\n", s)
        s = re.sub(r"(?<!^)\s(?=(?:I|II|III|IV|V)\.?\b)", "\n", s)
        s = re.sub(r"(?<!^)\s(?=\d{1,3}(?:[.,]\d{3}){2,}\b)", "\n", s)
        out_lines.extend([p.strip() for p in s.split("\n") if p.strip()])
    return "\n".join(out_lines)

def ocr_image_to_text_tsv(img_bgr, ocr_lang: str, ocr_cfg: str) -> str:
    """OCR ·∫£nh b·∫±ng TSV reflow (ƒë·ªçc t·ªët h∆°n cho b·∫£ng / scan)."""
    try:
        cfg = (ocr_cfg or "").strip()
        cfg = re.sub(r"--psm\s+\d+", "", cfg)
        cfg = (cfg + " --psm 4 preserve_interword_spaces=1").strip()
        tsv = pytesseract.image_to_data(img_bgr, lang=ocr_lang, config=cfg, output_type=TessOutput.DICT)
        txt = reflow_lines_from_tsv_dict(tsv)
        return clean_txt_chars(txt)
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói OCR TSV: {e}")
        return ""


# =========================
# ‚öôÔ∏è ƒê·ªåC ·∫¢NH & PDF SCAN
# =========================
def pdf_to_texts(pdf_path: str, dpi: int = 400,
                 ocr_lang: str = OCR_LANG_DEFAULT, ocr_cfg: str = OCR_CFG_DEFAULT,
                 start_page: Optional[int] = None, end_page: Optional[int] = None) -> List[Tuple[int, str]]:
    texts = []
    try:
        pages = convert_from_path(pdf_path, dpi=dpi)
        total = len(pages)
        s = start_page or 1
        e = end_page or total
        s = max(1, s); e = min(total, e)
        for i, page in enumerate(pages, start=1):
            if not (s <= i <= e):
                continue
            img = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)
            txt = ocr_image_to_text_tsv(img, ocr_lang, ocr_cfg)
            texts.append((i, txt))
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói PDF {pdf_path}: {e}")
    return texts


# =========================
# ‚öôÔ∏è ƒê·ªåC FILE KH√îNG C·∫¶N OCR (DOCX, EXCEL, CSV, TXT)
# =========================
def read_text_file(path: str) -> str:
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        return f.read()

def read_docx_file(path: str) -> str:
    if docx is None:
        raise ImportError("‚ö†Ô∏è C·∫ßn c√†i python-docx ƒë·ªÉ ƒë·ªçc DOCX.")
    doc = docx.Document(path)
    return "\n".join(p.text for p in doc.paragraphs if p.text.strip())

def read_excel_or_csv(path: str, mode: str = "summary") -> str:
    ext = Path(path).suffix.lower()
    texts = []
    try:
        if ext == ".csv":
            df = pd.read_csv(path, dtype=str)
            dfs = {"CSV": df}
        else:
            xls = pd.ExcelFile(path, engine="openpyxl")
            dfs = {sheet: pd.read_excel(xls, sheet_name=sheet, dtype=str)
                   for sheet in xls.sheet_names}

        for sheet_name, df in dfs.items():
            if df.empty:
                continue
            df = df.fillna("").astype(str)
            if mode == "raw":
                headers = list(df.columns)
                header_line = " | ".join(headers)
                rows = [" | ".join(row.values) for _, row in df.iterrows()]
                sheet_text = f"\n\n========== SHEET: {sheet_name.upper()} ==========\n{header_line}\n" + "\n".join(rows)
            else:
                df = df.loc[:, ~df.columns.str.contains("^Unnamed")]
                headers = list(df.columns)
                sheet_text = [f"\n========== SHEET: {sheet_name.upper()} =========="]
                sheet_text.append(f"C√°c c·ªôt g·ªìm: {', '.join(headers)}.")
                for _, row in df.iterrows():
                    if not any(v.strip() for v in row.values):
                        continue
                    pairs = [f"{h}: {v}" for h, v in row.items() if v.strip()]
                    sheet_text.append("; ".join(pairs))
                sheet_text = "\n".join(sheet_text)
            texts.append(sheet_text.strip())

        return "\n\n".join(texts).strip()
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc {path}: {e}")
        return ""


# =========================
# ‚öôÔ∏è GHI OUTPUT
# =========================
def save_output_text_and_meta(text: str, meta: dict, out_txt: str, out_meta: str):
    ensure_dir(os.path.dirname(out_txt))
    with open(out_txt, "w", encoding="utf-8") as f:
        f.write(text)
    with open(out_meta, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    print(f"üìù Saved: {os.path.basename(out_txt)}, {os.path.basename(out_meta)}")


# =========================
# ‚öôÔ∏è X·ª¨ L√ù FILE CH√çNH
# =========================
def process_file(file_path: str, input_root: str, output_root: str,
                 ocr_lang: str, ocr_cfg: str, dpi: int = 400,
                 start_page: Optional[int] = None, end_page: Optional[int] = None,
                 excel_mode: str = "summary"):

    rel_path = os.path.relpath(file_path, input_root)
    base = Path(file_path).stem
    out_dir = os.path.join(output_root, os.path.dirname(rel_path))
    ensure_dir(out_dir)

    ext = Path(file_path).suffix.lower()
    text_outputs = []

    if ext in [".jpg", ".jpeg", ".png", ".tif", ".tiff", ".bmp"]:
        img = cv2.cvtColor(np.array(Image.open(file_path).convert("RGB")), cv2.COLOR_RGB2BGR)
        txt = ocr_image_to_text_tsv(img, ocr_lang, ocr_cfg)
        text_outputs = [(1, txt)]

    elif ext == ".pdf":
        all_pages = convert_from_path(file_path, dpi=dpi,
                                    first_page=start_page or 1,
                                    last_page=end_page or (start_page or 1))
        total = len(all_pages)
        print(f"üìÑ {os.path.basename(file_path)} ‚Üí OCR {total} trang (t·ª´ {start_page or 1} ƒë·∫øn {end_page or total})")

        for idx, page in enumerate(tqdm(all_pages, desc=f"OCR {os.path.basename(file_path)}", ncols=80)):
            i = (start_page or 1) + idx
            img = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)
            t0 = time.perf_counter()
            txt = ocr_image_to_text_tsv(img, ocr_lang, ocr_cfg)
            t1 = time.perf_counter()
            print(f"üïì Trang {i} ho√†n t·∫•t ({t1 - t0:.1f}s)")
            text_outputs.append((i, txt))

    elif ext in [".doc", ".docx"]:
        try:
            txt = read_docx_file(file_path)
            text_outputs = [(1, txt)]
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói DOCX: {e}")

    elif ext in [".xls", ".xlsx", ".csv"]:
        txt = read_excel_or_csv(file_path, mode=excel_mode)
        text_outputs = [(1, txt)]

    elif ext == ".txt":
        txt = read_text_file(file_path)
        text_outputs = [(1, txt)]

    else:
        print(f"‚ö†Ô∏è B·ªè qua (ƒë·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£): {file_path}")
        return

    # Ghi k·∫øt qu·∫£
    if len(text_outputs) > 1:
        combined_text = "\n\n".join(t for _, t in text_outputs if t.strip())
        page_range = f"{start_page or 1}-{end_page or (start_page or 1)}"
        out_txt = os.path.join(out_dir, f"{base}_page{page_range}_text.txt")
        out_meta = os.path.join(out_dir, f"{base}_page{page_range}_meta.json")
        meta = {
            "file": base,
            "page_range": page_range,
            "page_count": len(text_outputs),
            "source_path": os.path.abspath(file_path),
            "language": detect_language(combined_text),
            "ocr_lang": ocr_lang,
            "ocr_cfg": ocr_cfg,
            "text_sha1": _sha1_text(combined_text),
        }
        save_output_text_and_meta(combined_text, meta, out_txt, out_meta)
    else:
        for page_no, txt in text_outputs:
            out_txt = os.path.join(out_dir, f"{base}_page{page_no}_text.txt")
            out_meta = os.path.join(out_dir, f"{base}_page{page_no}_meta.json")
            meta = {
                "file": base,
                "page": page_no,
                "source_path": os.path.abspath(file_path),
                "language": detect_language(txt),
                "ocr_lang": ocr_lang,
                "ocr_cfg": ocr_cfg,
                "text_sha1": _sha1_text(txt),
            }
            save_output_text_and_meta(txt, meta, out_txt, out_meta)


# =========================
# ‚öôÔ∏è MAIN ENTRYPOINT
# =========================
def main():
    parser = argparse.ArgumentParser("A1 ‚Äî OCR ƒëa ƒë·ªãnh d·∫°ng (Text only, c√≥ TSV reflow cho b·∫£ng)")
    parser.add_argument("--input", type=str, default=INPUT_DIR_DEFAULT, help="Th∆∞ m·ª•c input")
    parser.add_argument("--out", type=str, default=OUTPUT_DIR_DEFAULT, help="Th∆∞ m·ª•c output")
    parser.add_argument("--ocr-lang", type=str, default=OCR_LANG_DEFAULT)
    parser.add_argument("--ocr-cfg", type=str, default=OCR_CFG_DEFAULT)
    parser.add_argument("--dpi", type=int, default=400)
    parser.add_argument("--clean", choices=["y","a","n","ask"], default="ask")
    parser.add_argument("--start", type=int, default=None, help="Trang b·∫Øt ƒë·∫ßu (ch·ªâ √°p d·ª•ng cho PDF)")
    parser.add_argument("--end", type=int, default=None, help="Trang k·∫øt th√∫c (ch·ªâ √°p d·ª•ng cho PDF)")
    parser.add_argument("--excel-mode", choices=["raw", "summary"], default="summary",
                        help="C√°ch ƒë·ªçc Excel: raw=gi·ªØ nguy√™n, summary=l√†m s·∫°ch ƒë·ªÉ vector store")

    args = parser.parse_args()
    START_PAGE, END_PAGE = args.start, args.end

    if os.path.exists(args.out):
        choice = args.clean
        if choice == "ask":
            choice = input(f"‚ö†Ô∏è Output '{args.out}' ƒë√£ t·ªìn t·∫°i. y=xo√°, a=append, n=b·ªè qua: ").strip().lower()
        if choice == "y":
            shutil.rmtree(args.out, ignore_errors=True)
            print(f"üóëÔ∏è ƒê√£ xo√° {args.out}")
        elif choice == "a":
            global APPEND_MODE
            APPEND_MODE = True
            print(f"‚ûï Gi·ªØ {args.out}, ch·ªâ ghi file m·ªõi.")
        elif choice == "n":
            print("‚è≠Ô∏è B·ªè qua to√†n b·ªô."); return
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá."); return

    ensure_dir(args.out)
    files = glob.glob(os.path.join(args.input, "**", "*.*"), recursive=True)
    if not files:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file n√†o trong input."); return

    print(f"üìÇ Input: {args.input}")
    print(f"üì¶ Output: {args.out}")
    print(f"üßÆ T·ªïng s·ªë file: {len(files)}")
    print(f"üß≠ Gi·ªõi h·∫°n trang PDF: {START_PAGE or 1} ‚Üí {END_PAGE or 't·∫•t c·∫£'}")
    has_excel = any(f.lower().endswith((".xls", ".xlsx", ".csv")) for f in files)
    if has_excel:
        print(f"üìä Ch·∫ø ƒë·ªô ƒë·ªçc Excel: {args.excel_mode}")

    for f in files:
        process_file(f, args.input, args.out, args.ocr_lang, args.ocr_cfg,
                     dpi=args.dpi, start_page=START_PAGE, end_page=END_PAGE,
                     excel_mode=args.excel_mode)

    print("\n‚úÖ Ho√†n t·∫•t OCR. Ki·ªÉm tra *_text.txt v√† *_meta.json trong th∆∞ m·ª•c output.")


if __name__ == "__main__":
    main()
